# âœ‹ Gesture Control System using MediaPipe (Pretrained Model)

This project implements a real-time **gesture recognition system** using **Google MediaPipe** and pretrained models. It detects and classifies hand gestures from webcam input and maps them to specific control actions (e.g., volume control, screen navigation, system commands).

## ğŸ¯ Project Objective

The aim is to build a lightweight and fast **gesture-based control interface** using prebuilt models from MediaPipe for:

- **Hand detection & tracking**
- **Gesture classification**
- **Custom gesture-to-command mapping**

This system can be extended to control applications such as media players, presentations, or smart home devices.

---

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **MediaPipe** â€“ for hand tracking and landmarks
- **OpenCV** â€“ for video capture and visualization
- **NumPy** â€“ for landmark processing
- **PyAutoGUI / OS commands** â€“ for executing gestures as system-level controls

---

## ğŸ“ Directory Structure
ğŸ“¦gesture-control-mediapipe
â”£ ğŸ“‚models/ # Optional: Custom pretrained models (if extended)
â”£ ğŸ“‚utils/ # Landmark extraction, gesture mapping
â”£ ğŸ“œgesture_controller.py # Main script
â”£ ğŸ“œREADME.md # Documentation
â”£ ğŸ“œrequirements.txt # Python dependencies
â”— ğŸ“œgesture_mapping.json # Config file for gesture-action mapping

## ğŸ§ª Example Gestures
Gesture	Action
Thumbs up	Volume up
Palm open	Pause/Play media
Index + Middle	Scroll down
Fist	Screen lock

All mappings are configurable in gesture_mapping.json.

## ğŸ§  Extending the Project
Add more gestures using angle-based classification or a small custom ML model

Train with TensorFlow or PyTorch for more complex gestures

Integrate with smart devices or presentation tools (e.g., PowerPoint, VLC, Zoom)

## ğŸ“œ License
This project is licensed under the MIT License. See the LICENSE file for details.

## ğŸ™‹â€â™€ï¸ Author
Kavya Sharma
AI/ML Enthusiast | Computer Science
kavyasharmanishu@gmail.com
